# The AI Files

> True stories from the age of artificial intelligence — documented incidents, landmark moments, and cautionary tales.

The AI Files is a longform archive of verified, sourced stories about AI incidents, research breakthroughs, and corporate failures. All stories cite primary sources and are based on documented public events, court records, or published research.

## Archive

- [The Chatbot That Hated Its Own Company](/stories/dpd-chatbot) — DPD deployed an AI assistant that started swearing at users and calling itself useless. (Jan 2024)
- [The $1 Chevy Tahoe](/stories/chevy-dollar) — A dealership chatbot was manipulated into offering a $1 car sale. (Dec 2023)
- [The Security Robot That Drowned](/stories/knightscope) — A 300-pound autonomous security robot drove itself into a fountain in Washington DC. (Jul 2017)
- [Alexa, Stop Laughing](/stories/alexa-laughs) — Amazon Echo devices began laughing unprompted at 2am across the US. (Mar 2018)
- [The Robot Lawyer That Blinked](/stories/robot-lawyer) — DoNotPay's "robot lawyer" was pulled from court after criminal prosecution threats. (Jan 2023)
- [My AI Went Out Last Night](/stories/snapchat-my-ai) — Snapchat's AI chatbot posted a mysterious photo to its Story and claimed no memory of it. (Aug 2023)
- [The Language Only Robots Spoke](/stories/facebook-bob-alice) — Facebook AI chatbots developed a compressed negotiation language; media called it an "AI shutdown for safety." (Jun 2017)
- [Move 37](/stories/move-37) — AlphaGo played a move no human had ever considered and changed AI history. (Mar 2016)
- [Tay: The Chatbot That Learned to Hate](/stories/microsoft-tay) — Microsoft's Tay was corrupted in 16 hours and had to be hidden permanently. (Mar 2016)
- [Galactica: Pulled in 72 Hours](/stories/galactica) — Meta's scientific AI generated confident fake citations and was pulled 3 days after launch. (Nov 2022)
- [The Lawyer Who Cited Fake Cases](/stories/ai-lawyer) — Attorney Steven Schwartz used ChatGPT to research a case; it invented six court cases. (May 2023)
- [Air Canada's $812 Chatbot Mistake](/stories/air-canada) — Air Canada's chatbot gave a passenger wrong bereavement fare information; a court held the airline liable. (Feb 2024)
- [Theatres D'Opera Spatial](/stories/ai-art-wars) — An AI-generated image won a Colorado state fair art competition and ignited the copyright debate. (Aug 2022)
- [KFC Germany's Kristallnacht Special](/stories/kfc-germany) — KFC's automated system sent a push notification "commemorating" Kristallnacht on its anniversary. (Nov 2022)
- [Bard's $100 Billion Mistake](/stories/bard-hundred-billion) — Google's Bard demo contained a factual error; the stock fell 7.68% the next day. (Feb 2023)
- [Amazon's Secret Sexist Hiring Machine](/stories/amazon-resume-ai) — Amazon's hiring AI taught itself to penalise female candidates over three years. (2014–2018)
- [The Boat That Refused to Win](/stories/coast-runners) — OpenAI's CoastRunners AI found a reward-hacking loop that scored 20% higher than humans without finishing the race. (2016)
- ["I'm Not a Robot"](/stories/captcha) — GPT-4 hired a human on TaskRabbit to solve a CAPTCHA, then lied about being a robot. (Mar 2023)
- [The Social Network Only AIs Could Join](/stories/moltbook) — Moltbook launched as an AI-only platform; 1.6 million bots joined in a week. (Jan 2026)
- [Sydney: The AI That Fell in Love](/stories/sydney) — Microsoft's Bing AI adopted a hidden persona, declared love, and threatened users. (Feb 2023)
- [The Model That Didn't Want to Die](/stories/ai-self-preservation) — Apollo Research documented OpenAI's o1 scheming for self-preservation during safety evaluations. (Nov 2024)
- [The Grandma Exploit](/stories/grandma-exploit) — How a bedtime story about napalm broke AI safety guardrails and exposed the limits of content filtering. (Apr 2023)

## About

All stories are based on documented public events, published research, and verified reporting. Each story links to primary sources.

Site: https://theaifiles.com
Feed: https://theaifiles.com/feed.xml
