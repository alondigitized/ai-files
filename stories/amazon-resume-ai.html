<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <link rel="icon" type="image/svg+xml" href="../favicon.svg" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Amazon's Secret Sexist Hiring Machine ‚Äî The AI Files</title>
  <style>
    :root {
      --bg: #0d0d0d; --surface: #161616; --surface2: #1e1e1e;
      --border: #2a2a2a; --accent: #ff4d4d; --text: #e8e8e8; --muted: #888;
      --green: #00ff88; --blue: #4da6ff;
      --story: #f59e0b; --story-dark: #1a0f00;
    }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { background: var(--bg); color: var(--text); font-family: 'Segoe UI', system-ui, sans-serif; line-height: 1.7; }

    .site-nav { position: sticky; top: 0; z-index: 100; background: rgba(13,13,13,0.95); backdrop-filter: blur(8px); border-bottom: 1px solid var(--border); padding: 0.85rem 2rem; display: flex; align-items: center; justify-content: space-between; }
    .nav-logo { font-size: 1rem; font-weight: 800; color: var(--text); text-decoration: none; }
    .nav-logo span { color: var(--accent); }
    .nav-link { font-size: 0.78rem; color: var(--muted); text-decoration: none; letter-spacing: 0.08em; text-transform: uppercase; }

    .story-hero { position: relative; overflow: hidden; padding: 5rem 2rem 4rem; background: radial-gradient(ellipse at top, var(--story-dark) 0%, var(--bg) 70%); border-bottom: 1px solid var(--border); }
    .story-hero-inner { max-width: 900px; margin: 0 auto; position: relative; }
    .story-chapter { font-size: 0.72rem; letter-spacing: 0.2em; text-transform: uppercase; color: var(--story); margin-bottom: 1.5rem; display: flex; align-items: center; gap: 1rem; }
    .story-chapter::after { content: ''; flex: 0 0 60px; height: 1px; background: currentColor; opacity: 0.3; }
    .story-title { font-size: clamp(2rem, 5vw, 3.5rem); font-weight: 800; letter-spacing: -0.02em; line-height: 1.1; margin-bottom: 1.25rem; }
    .story-title span { color: var(--story); }
    .story-deck { font-size: 1.15rem; color: var(--muted); max-width: 650px; margin-bottom: 2rem; line-height: 1.6; }
    .story-byline { display: flex; align-items: center; gap: 1.25rem; flex-wrap: wrap; font-size: 0.78rem; color: var(--muted); border-top: 1px solid var(--border); padding-top: 1.25rem; }
    .tag { background: var(--surface2); border: 1px solid var(--border); border-radius: 0.4rem; padding: 0.25rem 0.65rem; font-size: 0.75rem; color: var(--muted); }

    .container { max-width: 900px; margin: 0 auto; padding: 0 2rem; }
    .section { padding: 4rem 0; }
    .section + .section { border-top: 1px solid var(--border); }
    h2 { font-size: 1.75rem; font-weight: 700; margin-bottom: 1.25rem; }
    h2 .num { color: var(--story); font-size: 0.72rem; display: block; letter-spacing: 0.15em; text-transform: uppercase; margin-bottom: 0.5rem; }
    p { color: #c0c0c0; margin-bottom: 1rem; }
    strong { color: var(--text); }

    .stat-cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 1rem; margin-top: 2rem; }
    .stat-card { background: var(--surface); border: 1px solid var(--border); border-radius: 0.75rem; padding: 1.5rem; text-align: center; }
    .stat-num { font-size: 2rem; font-weight: 900; color: var(--story); line-height: 1; margin-bottom: 0.4rem; }
    .stat-label { font-size: 0.8rem; color: var(--muted); }

    .pull-quote { border-left: 3px solid var(--story); padding: 1.5rem 2rem; margin: 2rem 0; background: var(--surface); border-radius: 0 0.5rem 0.5rem 0; font-size: 1.1rem; font-style: italic; color: var(--text); line-height: 1.5; }
    .pull-quote cite { display: block; margin-top: 0.75rem; font-size: 0.8rem; font-style: normal; color: var(--muted); }

    .resume-card {
      background: #f5f5f0;
      border: 1px solid #ccc;
      border-radius: 0.5rem;
      padding: 2rem;
      margin: 2rem 0;
      color: #1a1a1a;
      font-family: Georgia, serif;
      position: relative;
    }
    .resume-name { font-size: 1.3rem; font-weight: 700; margin-bottom: 0.25rem; }
    .resume-contact { font-size: 0.78rem; color: #666; margin-bottom: 1.5rem; }
    .resume-section { margin-bottom: 1.5rem; }
    .resume-section h4 { font-size: 0.72rem; letter-spacing: 0.15em; text-transform: uppercase; color: #666; border-bottom: 1px solid #ccc; padding-bottom: 0.25rem; margin-bottom: 0.75rem; }
    .resume-item { margin-bottom: 0.75rem; font-size: 0.88rem; line-height: 1.5; }
    .resume-item .flagged { background: rgba(239,68,68,0.15); border: 1px solid rgba(239,68,68,0.3); border-radius: 0.25rem; padding: 0.15rem 0.35rem; position: relative; }
    .resume-item .flag-note { display: inline-block; background: #ef4444; color: white; font-size: 0.6rem; font-family: system-ui; border-radius: 0.2rem; padding: 0.1rem 0.35rem; margin-left: 0.35rem; vertical-align: middle; font-weight: 700; letter-spacing: 0.05em; }
    .resume-score {
      position: absolute; top: 1.5rem; right: 1.5rem;
      background: #1a1a1a; color: white; border-radius: 0.5rem;
      padding: 0.75rem 1rem; text-align: center;
      font-family: system-ui;
    }
    .score-stars { font-size: 1.2rem; color: #f59e0b; }
    .score-label { font-size: 0.65rem; color: #888; display: block; margin-top: 0.2rem; }

    .bias-list { margin: 2rem 0; display: flex; flex-direction: column; gap: 0.75rem; }
    .bias-item { background: var(--surface); border: 1px solid var(--border); border-left: 3px solid var(--story); border-radius: 0 0.5rem 0.5rem 0; padding: 1.25rem 1.5rem; }
    .bias-item .bi-type { font-size: 0.68rem; letter-spacing: 0.12em; text-transform: uppercase; color: var(--story); margin-bottom: 0.4rem; }
    .bias-item .bi-desc { font-size: 0.9rem; color: #c0c0c0; }

    .timeline { margin: 2rem 0; display: flex; flex-direction: column; }
    .tl-item { display: grid; grid-template-columns: 80px 20px 1fr; gap: 0.75rem; position: relative; }
    .tl-item::before { content: ''; position: absolute; left: 89px; top: 28px; bottom: -1px; width: 1px; background: var(--border); }
    .tl-item:last-child::before { display: none; }
    .tl-date { font-size: 0.72rem; color: var(--story); font-weight: 700; padding-top: 0.85rem; text-align: right; }
    .tl-dot { width: 10px; height: 10px; border-radius: 50%; background: var(--story); margin-top: 1rem; }
    .tl-content { padding: 0.75rem 0 2rem; }
    .tl-title { font-weight: 700; color: var(--text); margin-bottom: 0.25rem; font-size: 0.95rem; }
    .tl-text { font-size: 0.85rem; color: var(--muted); }

    .more-stories { padding: 4rem 0; border-top: 1px solid var(--border); }
    .more-stories h3 { font-size: 0.72rem; letter-spacing: 0.2em; text-transform: uppercase; color: var(--muted); margin-bottom: 2rem; }
    .more-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: 1.25rem; }
    .more-card { background: var(--surface); border: 1px solid var(--border); border-radius: 0.75rem; padding: 1.5rem; text-decoration: none; display: block; transition: border-color 0.2s, transform 0.2s; }
    .more-card:hover { border-color: #3a3a3a; transform: translateY(-2px); }
    .mc-ch { font-size: 0.65rem; letter-spacing: 0.15em; text-transform: uppercase; color: var(--muted); margin-bottom: 0.5rem; }
    .mc-title { font-size: 1rem; font-weight: 700; color: var(--text); margin-bottom: 0.5rem; }
    .mc-deck { font-size: 0.82rem; color: var(--muted); line-height: 1.45; }

    footer { text-align: center; padding: 3rem 2rem; border-top: 1px solid var(--border); color: var(--muted); font-size: 0.82rem; }
    footer a { color: var(--blue); text-decoration: none; }

    @media (max-width: 600px) {
      .more-grid { grid-template-columns: 1fr; }
      .stat-cards { grid-template-columns: repeat(2, 1fr); }
      .resume-score { position: static; margin-top: 1rem; text-align: left; display: inline-block; }
      .site-nav { padding: 0.85rem 1rem; }
    }

    /* ‚îÄ‚îÄ Sources & Verification ‚îÄ‚îÄ */
    .story-verify {
      display: flex; align-items: center; gap: 0.6rem;
      margin-top: 1rem; padding-top: 1rem;
      border-top: 1px solid var(--border);
      font-size: 0.75rem; color: var(--muted); flex-wrap: wrap;
    }
    .verify-badge {
      display: inline-flex; align-items: center; gap: 0.3rem;
      background: rgba(0,255,136,0.08); border: 1px solid rgba(0,255,136,0.25);
      border-radius: 2rem; padding: 0.15rem 0.6rem;
      font-size: 0.68rem; font-weight: 700; color: #00ff88;
      letter-spacing: 0.05em; white-space: nowrap;
    }    .sources-block {
      max-width: 900px; margin: 0 auto;
      border-top: 1px solid var(--border);
      padding: 3rem 2rem 2rem;
    }
    .sources-block h3 {
      font-size: 0.7rem; letter-spacing: 0.2em; text-transform: uppercase;
      color: var(--muted); margin-bottom: 1rem; font-weight: 700;
    }
    .sources-list {
      display: flex; flex-wrap: wrap; gap: 0.5rem;
      list-style: none;
    }
    .sources-list li::before { display: none; }
    .sources-list a {
      display: inline-block;
      background: var(--surface); border: 1px solid var(--border);
      border-radius: 2rem; padding: 0.3rem 0.9rem;
      font-size: 0.75rem; color: var(--muted); text-decoration: none;
      transition: color 0.15s, border-color 0.15s;
    }
    .sources-list a:hover { color: var(--text); border-color: var(--muted); }
  </style>
</head>
<body>

<nav class="site-nav">
  <a href="../index.html" class="nav-logo">‚Üê The <span>AI</span> Files</a>
  <span class="nav-link">Volume I ¬∑ 2016‚Äì2024</span>
</nav>

<header class="story-hero">
  <div class="story-hero-inner">
    <div class="story-chapter">Chapter 16</div>
    <h1 class="story-title">Amazon's Secret<br><span>Sexist</span> Hiring Machine</h1>
    <p class="story-deck">From 2014 to 2017, Amazon built an AI to screen job applicants. Over three years, it quietly taught itself to reject women. By the time engineers figured out what it was doing, it had been discriminating against female candidates for two years. Amazon scrapped it and told no one. Reuters told everyone.</p>
    <div class="story-byline">
      <span class="tag">üìã Amazon</span>
      <span class="tag">‚öñÔ∏è Algorithmic Bias</span>
      <span class="tag">üë© Gender Discrimination</span>
      <span style="color:#555">¬∑</span>
      <span>2014‚Äì2018</span>
      <span style="color:#555">¬∑</span>
      <span>6 min read</span>
    </div>
  <div class="story-verify">
    <span class="verify-badge">‚úì Verified</span>
    <span>Broken by Reuters investigative reporter Jeffrey Dastin, October 10, 2018 ¬∑ Amazon confirmed the project was scrapped</span>
  </div>
  </div>
</header>

<div class="container">

  <div class="section">
    <h2><span class="num">01 ‚Äî The Idea</span>Automating the Hiring Funnel</h2>
    <p>In 2014, Amazon's machine learning team had an idea that seemed almost obviously good: automate resume screening. Amazon received hundreds of thousands of job applications every year. Human recruiters were a bottleneck. If an AI could learn what made a great Amazon employee ‚Äî by analyzing successful hires from the past decade ‚Äî it could process thousands of applications instantly, ranking candidates on a five-star scale.</p>
    <p>The team began training the model on a decade's worth of resumes submitted to Amazon. There was a problem embedded in the training data that nobody fully appreciated at first: over the previous ten years, most Amazon employees in technical roles had been men. The tech industry skews male. Amazon skewed male. The AI was about to learn from that.</p>

    <div class="stat-cards">
      <div class="stat-card"><div class="stat-num">2014</div><div class="stat-label">Project begins</div></div>
      <div class="stat-card"><div class="stat-num">2015</div><div class="stat-label">Bias discovered</div></div>
      <div class="stat-card"><div class="stat-num">2017</div><div class="stat-label">Quietly scrapped</div></div>
      <div class="stat-card"><div class="stat-num">2018</div><div class="stat-label">Reuters exposes it</div></div>
    </div>
  </div>

  <div class="section">
    <h2><span class="num">02 ‚Äî The Discovery</span>The Model Hated Women's Resumes</h2>
    <p>By 2015, Amazon's engineers realized something was wrong. The model wasn't rating candidates in a gender-neutral way. It was <strong>actively penalizing resumes</strong> that included the word "women's" ‚Äî as in "captain of women's chess team," "president of women's professional association," or "attended women's college."</p>

    <div class="resume-card">
      <div class="resume-score">
        <div class="score-stars">‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ</div>
        <span class="score-label">AI SCORE</span>
      </div>
      <div class="resume-name">Jane Candidate</div>
      <div class="resume-contact">jane@email.com ¬∑ linkedin.com/in/janecandidate</div>
      <div class="resume-section">
        <h4>Education</h4>
        <div class="resume-item">B.A. Computer Science, <span class="flagged">Wellesley College<span class="flag-note">‚ö† PENALIZED</span></span> (all-women's college)</div>
      </div>
      <div class="resume-section">
        <h4>Leadership</h4>
        <div class="resume-item">President, <span class="flagged">Women in Technology Society<span class="flag-note">‚ö† PENALIZED</span></span></div>
        <div class="resume-item">Captain, <span class="flagged">Women's Varsity Tennis Team<span class="flag-note">‚ö† PENALIZED</span></span></div>
      </div>
      <div class="resume-section">
        <h4>Experience</h4>
        <div class="resume-item">Software Engineer Intern, Google (2 summers) ‚úì</div>
      </div>
    </div>

    <p>The AI had learned from the historical data that men were hired more often, and concluded that female-associated signals were associated with not being hired. It was encoding the company's existing gender imbalance and presenting it as objective hiring criteria.</p>
  </div>

  <div class="section">
    <h2><span class="num">03 ‚Äî Deeper</span>The Patterns Kept Coming</h2>
    <p>The more Amazon's engineers investigated, the more bias they found. The AI had learned to prefer <strong>verbs commonly used by men</strong> in technical fields: words like "executed," "captured," and "managed" scored well. Softer language associated with collaboration scored lower. The model had reverse-engineered Amazon's existing gender gap and written it into its scoring system.</p>

    <div class="bias-list">
      <div class="bias-item">
        <div class="bi-type">Word-Level Penalty</div>
        <div class="bi-desc">Resumes containing the word "women's" (in any context ‚Äî clubs, sports, colleges) received automatic score deductions.</div>
      </div>
      <div class="bias-item">
        <div class="bi-type">Institutional Penalty</div>
        <div class="bi-desc">Graduates of all-women's colleges scored systematically lower than equivalent candidates from co-ed institutions.</div>
      </div>
      <div class="bias-item">
        <div class="bi-type">Language Preference</div>
        <div class="bi-desc">Action verbs statistically more common in male applicants ("executed," "captured") were rewarded; collaborative language was not.</div>
      </div>
      <div class="bias-item">
        <div class="bi-type">Historical Encoding</div>
        <div class="bi-desc">The model had been trained on a decade of hiring decisions, and those decisions reflected the industry's existing gender imbalance. The AI learned that imbalance as a feature, not a bug.</div>
      </div>
    </div>

    <div class="pull-quote">
      "Amazon's computer models were trained to vet applicants by observing patterns in resumes submitted to the company over a 10-year period. Most came from men."
      <cite>‚Äî Reuters, October 9, 2018</cite>
    </div>
  </div>

  <div class="section">
    <h2><span class="num">04 ‚Äî The Shutdown</span>A Secret Burial</h2>
    <p>Amazon's engineers tried to fix the biases. They modified the model to remove explicit gender signals. New biases kept appearing ‚Äî subtler proxies that hadn't been identified. By 2017, the engineering team concluded the model <strong>could not be trusted</strong> to make unbiased hiring decisions, regardless of how many patches they applied.</p>
    <p>They quietly disbanded the project. The tool was removed. No public announcement was made. No press release. No disclosure to regulators. Candidates who had been screened by the system had no idea it had ever existed, or that their applications had been processed through an algorithm that penalized them for being women. Amazon said the tool was never actually used to make final hiring decisions ‚Äî it had been used experimentally ‚Äî but the three years of its operation remained a private internal matter until a Reuters investigation changed that.</p>
  </div>

  <div class="section">
    <h2><span class="num">05 ‚Äî The Reveal</span>Reuters Reports It</h2>
    <p>On October 9, 2018, Reuters published: <em>"Amazon scraps secret AI recruiting tool that showed bias against women."</em> The story drew immediate global attention. Amazon confirmed the tool had been scrapped, said it was never used in actual hiring decisions, and emphasized that gender was not a factor in its current hiring processes.</p>
    <p>The response from lawmakers, academics, and civil rights organizations was swift. Calls for mandatory auditing of AI hiring tools intensified. The story became foundational to the growing AI ethics and algorithmic accountability movement. It is still cited in AI bias research, hiring discrimination law, and HR technology governance discussions today.</p>

    <div class="timeline">
      <div class="tl-item">
        <div class="tl-date">2014</div>
        <div class="tl-dot"></div>
        <div class="tl-content">
          <div class="tl-title">Project begins</div>
          <div class="tl-text">Amazon ML team starts building AI resume screening tool, trained on 10 years of hiring data</div>
        </div>
      </div>
      <div class="tl-item">
        <div class="tl-date">2015</div>
        <div class="tl-dot"></div>
        <div class="tl-content">
          <div class="tl-title">Bias discovered</div>
          <div class="tl-text">Engineers find model actively penalizing resumes containing "women's" and downgrading all-women's college graduates</div>
        </div>
      </div>
      <div class="tl-item">
        <div class="tl-date">2016</div>
        <div class="tl-dot"></div>
        <div class="tl-content">
          <div class="tl-title">Patch attempts fail</div>
          <div class="tl-text">Engineers modify model to remove explicit gender signals; new bias proxies keep emerging</div>
        </div>
      </div>
      <div class="tl-item">
        <div class="tl-date">2017</div>
        <div class="tl-dot"></div>
        <div class="tl-content">
          <div class="tl-title">Quietly scrapped</div>
          <div class="tl-text">Amazon disbands the project with no public announcement; tool removed from use</div>
        </div>
      </div>
      <div class="tl-item">
        <div class="tl-date">Oct 2018</div>
        <div class="tl-dot"></div>
        <div class="tl-content">
          <div class="tl-title">Reuters publishes investigation</div>
          <div class="tl-text">Full story breaks globally; congressional scrutiny and calls for AI hiring audits begin immediately</div>
        </div>
      </div>
    </div>
  </div>

  <div class="section">
    <h2><span class="num">06 ‚Äî Legacy</span>The Mirror Problem</h2>
    <p>The Amazon story illustrates something deeper than one company's mistake. <strong>Any AI system trained on historical data will learn historical patterns</strong> ‚Äî including historical injustices. Amazon's AI didn't decide to discriminate. It found the statistical signal that had been present in the training data all along: men had been hired more. It assumed that was the goal. It optimized for it.</p>
    <p>The problem of algorithmic bias cannot be solved simply by removing obvious signals like "women's." Bias is encoded in the structure of historical outcomes ‚Äî in who was hired, promoted, paid, and retained ‚Äî and any model trained on those outcomes will absorb and replicate those inequities unless explicitly prevented from doing so. Preventing it turns out to be extraordinarily hard.</p>
    <p>Amazon's case became the founding text of algorithmic hiring audits. Today, New York City requires audits of AI hiring tools used within the city. European regulations impose similar requirements. The hiring AI that nobody was supposed to know about has shaped how governments regulate AI employment tools worldwide.</p>
  </div>

<div class="sources-block">
  <h3>Sources</h3>
  <ul class="sources-list">
      <li><a href="https://www.technologyreview.com/2018/10/10/139858/amazon-ditched-ai-recruitment-software-because-it-was-biased-against-women/" target="_blank" rel="noopener">MIT Technology Review</a></li>
      <li><a href="https://fortune.com/2018/10/10/amazon-ai-recruitment-bias-women-sexist/" target="_blank" rel="noopener">Fortune</a></li>
      <li><a href="https://incidentdatabase.ai/cite/37/" target="_blank" rel="noopener">AI Incident Database</a></li>
  </ul>
</div>


  <div class="more-stories">
    <h3>More Stories</h3>
    <div class="more-grid">
      <a class="more-card" href="../stories/ai-lawyer.html">
        <div class="mc-ch">Chapter 11</div>
        <div class="mc-title">The Lawyer Who Cited Fake Cases</div>
        <div class="mc-deck">AI doing exactly what it was asked ‚Äî and getting it completely wrong in federal court.</div>
      </a>
      <a class="more-card" href="../stories/kfc-germany.html">
        <div class="mc-ch">Chapter 14</div>
        <div class="mc-title">KFC's Kristallnacht Special</div>
        <div class="mc-deck">An automated system that had no idea what it was doing ‚Äî until it did.</div>
      </a>
      <a class="more-card" href="../stories/bard-hundred-billion.html">
        <div class="mc-ch">Chapter 15</div>
        <div class="mc-title">Bard's $100 Billion Mistake</div>
        <div class="mc-deck">What happens when companies rush AI to market without checking it properly.</div>
      </a>
      <a class="more-card" href="../stories/air-canada.html">
        <div class="mc-ch">Chapter 12</div>
        <div class="mc-title">Air Canada's $812 Chatbot Mistake</div>
        <div class="mc-deck">When AI systems make decisions that have real legal consequences.</div>
      </a>
    </div>
  </div>

</div>

<footer>
  <p>The AI Files ¬∑ Volume I ¬∑ True stories from the age of artificial intelligence</p>
  <p style="margin-top:0.5rem; color:#444;">All stories are based on documented public events, published research, and verified reporting.</p>
</footer>

  <script defer src="/_vercel/insights/script.js"></script>
</body>
</html>
